<!DOCTYPE html>
<html>
<header>
    <title>ONNX Runtime JavaScript examples: Quick Start - Web (using bundler)</title>
</header>

<body>
    <canvas id="input-canvas" , width=224, height=224></canvas>
    <!--script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.webgpu.min.js"></script-->
    <script src="web_r/dist/ort.webgpu.min.js"></script>
    <script>
        //ort.env.logLevel = 'verbose';
        //ort.env.debug = true;
        const gModelName  = 'modified_albert-base-v2';
        function getFreeDimensionOverrides(modelName) {
            let freeDimensionOverrides = {};
            if (modelName === gModelName) {
                freeDimensionOverrides = {
                    batch_size: 1,sequence_length: 3,
                };
            }
            return freeDimensionOverrides;
        }
        async function main() {
            const buffer = new ArrayBuffer(24);
            const bigint64 = new BigInt64Array(buffer);
            bigint64[0] = 10n;
            bigint64[1] = 20n;
            bigint64[2] = 30n;
            const tensor = new ort.Tensor("int64", bigint64, [1,3]);

            // set option
            const option = {
                executionProviders: [
                    {
                        name: 'webgpu',
                    },
                ],
                graphOptimizationLevel: 'disabled',
            };
            // https://huggingface.co/unity/sentis-jets-text-to-speech/blob/main/jets-text-to-speech.onnx
            option.freeDimensionOverrides = getFreeDimensionOverrides(gModelName);
            option.enableGraphCapture = true;

            const modelName = gModelName;
            const modelPath = modelName + '.onnx';
            const session = await ort.InferenceSession.create(modelPath, option);
            let feeds = { attention_mask: tensor };
            const result = await session.run(feeds);
            console.log(result);
        }

        main();
    </script>
</body>

</html>
